# 优达学城(Udacity) - 机器学习算法工程师纳米学位
# 3- 非监督学习

快速浏览
- [首页](https://github.com/zhsam/Machine_Learning_Interview_Notes-Chinese)
- [机器学习基础](https://github.com/zhsam/Machine_Learning_Interview_Notes-Chinese/blob/master/1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md)
- [监督学习](https://github.com/zhsam/Machine_Learning_Interview_Notes-Chinese/blob/master/2-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.md)
- [非监督学习(本文)](https://github.com/zhsam/Machine_Learning_Interview_Notes-Chinese/blob/master/3-%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.md)
- [深度学习](https://github.com/zhsam/Machine_Learning_Interview_Notes-Chinese/blob/master/4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.md)
- [强化学习](https://github.com/zhsam/Machine_Learning_Interview_Notes-Chinese/blob/master/5-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.md)
- [毕业项目]()
- [看面试经验]()
- [课程项目](https://github.com/zhsam/Udacity-MachineLearningEngineer-nd)

## 课程目录
- 聚类
- 聚类迷你项目
- 层次聚类法与密度聚类
- 高斯混合模型与聚类验证
- 特征缩放
- PCA 主成分分析
- PAC迷你项目
- 随机投影与ICA
- 非监督学习自我评估
- [项目] 创建客户细分


### 4-1 聚类
非监督学习：从没有标签(Flag)的数据中，发现其架构
聚类 Clustering：根据数据的分布方式，进行群集
降维 Dimensionality Reduction：从二维空间，变成一条线

最常见的聚类算法：K-means

### 4-3 层次聚类法
**单连接聚类法 (Single Link Clustering)**

**全连接聚类法 (Complete Link Clustering)**

**平均连接聚类法 (Average Link Clustering)**

**凝聚聚类法 (Aggolomerative Clustering)**

**离差平方和法 (WARD's method)**
- sklearn层次聚类的默认算法
- 计算A，B的方法

**层次聚类在Python中的实践**
- 使用层次聚类 - sklearn
```
from sklearn import datasets, cluster

# Load dataset (鸢尾花数据集)
X =  dataset.load_iris().date[:10]

# Specify the parameter for the Clustering. 'ward', linkage
# is default. Can alsouse 'complete' or 'average'
clust = cluster.AggolomerativeClustering(n_cluster=3, linkage='ward')

labels = clust.fit_predict(X)

#labels now contains an array representing with cluster
# each point belongs to : [1 0 0 0 1 2 0 1 0 0]
```
- 画出层次树(dendrograms) - scipy

```
from scipy.cluster.hierarchy import dendrograms, ward, single
from sklearn import datasets
import matplotlib.pyplot as plt

# Load dataset
X =  dataset.load_iris().date[:10]

# Perform Clustering
linkage_matrix = ward(X)

# Plot Dendrogram
dendrogram(linkage_matrix)

plt.show()
```
**层次聚类(Hierarchical Clustering)的优缺点、示例**
> 优缺点

优点：
- 层次聚类的结果信息丰富 (Resulting Hierarchical representation can be very informative)
- 可以额外进行可视化 (Provides an additional ability to visualize)
- 如果数据集实际存在层次信息，会更加有意义 (Especially potent when the dataset contains real hierarchical relationaships(e.g.Evolutional Biology))

缺点：
- 对离群值很敏感 (Sensitive to outliers)
- 计算复杂度高 (Computationally Intensive O(N^2) )
> 示例

- 应用层次聚类探索不同种类真菌的分泌蛋白 ([ Using Hierarchical Clustering of Secreted Protein Families to Classify and Rank Candidate Effectors of Rust Fungi](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029847))
- 应用全连接聚类法 绘制人体微生物的图表 (Association between composition of the human gastrointestinal microbiome and development of fatty liver with choline deficiency)

**Quiz**
- Q：更容易导致细长的形状，而不一定是聚合或环形？
- A：单连接算法

- Q：分层聚类中的哪种连接方法是通过合并聚类来实现，并且这些聚类导致合并后在聚类中方差得到最小化的增加呢？
- A：离差平方和法



****
****
****
